{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\pisis\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\pisis\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\pisis\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\users\\pisis\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\pisis\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy in c:\\users\\pisis\\anaconda3\\lib\\site-packages (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from scipy) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in c:\\users\\pisis\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from seaborn) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: graphviz in c:\\users\\pisis\\anaconda3\\lib\\site-packages (0.20.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: xgboost in c:\\users\\pisis\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from xgboost) (1.11.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: lightgbm in c:\\users\\pisis\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from lightgbm) (1.11.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: catboost in c:\\users\\pisis\\anaconda3\\lib\\site-packages (1.2.5)\n",
      "Requirement already satisfied: graphviz in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from catboost) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from catboost) (2.1.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from catboost) (1.11.4)\n",
      "Requirement already satisfied: plotly in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\pisis\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Install list of libraries\n",
    "%pip install imbalanced-learn\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install scikit-learn\n",
    "%pip install scipy\n",
    "%pip install seaborn --upgrade\n",
    "%pip install graphviz\n",
    "%pip install xgboost\n",
    "%pip install lightgbm\n",
    "%pip install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1205360016.py, line 45)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[22], line 45\u001b[1;36m\u001b[0m\n\u001b[1;33m    RandomForestClassifier(bootstrap: False, max_depth: 29, max_features: \"log2\", min_samples_leaf: 1, min_samples_split: 2, n_estimators: 200)]\u001b[0m\n\u001b[1;37m                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from os import path, getcwd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from sklearn.feature_selection import VarianceThreshold, chi2, f_classif, SelectKBest, SelectFromModel\n",
    "from scipy.stats import kendalltau\n",
    "\n",
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "# from IPython.display import Image\n",
    "import graphviz\n",
    "\n",
    "subjects = [102, 104, 105, 107, 110, 111, 115, 116, 117, 118, 120, 126, 127, 130, 131, 132, 133, 135, 138, 141, 143, 144]\n",
    "col = ['1','2','3','Label', 'Frontal P3 mean', 'Frontal P3 STD', 'Posterior P3 mean', 'Posterior P3 STD', 'Frontal alpha mean', \n",
    "           'Posterior alpha mean', 'Alpha variability', 'Reaction time Mean', 'Reaction time variability', 'Accuracy', 'Frontal P3 log energy entropy', \n",
    "           'Frontal P3 Shannon entropy', 'Frontal P3 SURE entropy', 'Frontal P3 Skewness', 'Frontal P3 Kurtosis', 'Frontal alpha log energy entropy',\n",
    "           'Frontal alpha Shannon entropy', 'Frontal alpha SURE entropy', 'Frontal alpha Skewness', 'Frontal alpha Kurtosis', \n",
    "           'Posterior P3 log energy entropy', 'Posterior P3 Shannon entropy', 'Posterior P3 SURE entropy', 'Posterior P3 Skewness', 'Posterior P3 Kurtosis', \n",
    "           'Posterior alpha log energy entropy', 'Posterior alpha Shannon entropy', 'Posterior alpha SURE entropy', 'Posterior alpha Skewness',\n",
    "           'Posterior alpha Kurtosis'\n",
    "]\n",
    "cwd = getcwd()\n",
    "target_names = ['Task Unrelated Thought', 'Task Related Thought']\n",
    "results_file = 'Results.xlsx'\n",
    "\n",
    "# Fill this with the models you would like to test:\n",
    "# regressors = [LogisticRegression(max_iter=1800, random_state=42), RandomForestClassifier(random_state=42), GradientBoostingClassifier(random_state=42), SVC(random_state=42), KNeighborsClassifier(), \n",
    "            #   XGBClassifier(random_state=42), LGBMClassifier(random_state=42), CatBoostClassifier(random_state=42)]\n",
    "regressors = [CatBoostClassifier(random_state=42), \n",
    "              RandomForestClassifier(bootstrap= False, max_depth= 29, max_features= \"log2\", min_samples_leaf= 1, min_samples_split= 2, n_estimators= 200)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha variability and all with posterior features --> see performance,  \n",
    "Then include behavioural features: 'Reaction time Mean', 'Reaction time variability',and see how it performs\n",
    "\n",
    "Feature ranking algorithms (top 5, top 10 features)\n",
    "correlation matrix between features to identify important ** try first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all subject mat files, append TR and TUR structures to dataframe\n",
    "for a in subjects:\n",
    "    file = 'Feature_data_'+str(a)+'.mat'\n",
    "    #Absolute path to mat file:\n",
    "    #loc = os.path.join('C:/Users/pisis/OneDrive - University of Calgary/2024/AIRS/TR and TUT data',file)\n",
    "    loc = path.join(cwd, 'TR and TUT data', file)\n",
    "    subData = loadmat(loc)['data']\n",
    "    subData_TR = subData['TR'][0,0]\n",
    "    subData_TUR = subData['TUR'][0,0]\n",
    "    subDF_TR = pd.DataFrame(subData_TR, columns = col)\n",
    "    subDF_TUR = pd.DataFrame(subData_TUR, columns = col)\n",
    "    if a==subjects[0]:\n",
    "        totalDF = pd.concat([subDF_TR,subDF_TUR])\n",
    "    else:\n",
    "        totalDF = pd.concat([totalDF, subDF_TR])\n",
    "        totalDF = pd.concat([totalDF, subDF_TUR])\n",
    "\n",
    "#Show Data with NaN values:\n",
    "# print(totalDF[totalDF.isnull().any(axis=1)])\n",
    "# NOTE: Subject 109 has NaN values in the Reaction time Mean and Reaction time variability columns. Excluded from analysis.\n",
    "# totalDF.fillna(0, inplace=True)\n",
    "\n",
    "totalDF.reset_index(drop=True, inplace=True)\n",
    "# print(totalDF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and Normalize\n",
    "There are some [different normalization techniques](https://www.geeksforgeeks.org/ml-feature-scaling-part-2/), but all seem to give the same result in our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = totalDF.Label\n",
    "Y = Y - 1\n",
    "all_features = totalDF.iloc[:, 4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "Feature selection is for determining the most important features in our data. We compared all features, the alpha + posterior features, and finally, the alpha + posterior + behavioural features before using the built-in feature analysis (suggested by Sarah).  \n",
    "[There are many types of feature selection techniques](https://youtu.be/LTE7YbRexl8?si=xW9kJt1lciKEKwAW). \n",
    "1. Filter-based techniques:\n",
    "    - Correlation\n",
    "    - Variance threshold\n",
    "    - Chi squared\n",
    "    - Anova\n",
    "    - Information Gain\n",
    "2. Wrapper techniques:\n",
    "    - Recursive Feature Elimination (RFE)\n",
    "3. Embed techniques\n",
    "    - L1 & L2\n",
    "    - Pruning/Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_columns = ['Posterior P3 mean', 'Posterior P3 STD', 'Posterior alpha mean', 'Alpha variability', 'Accuracy', 'Posterior P3 log energy entropy', \n",
    "              'Posterior P3 Shannon entropy', 'Posterior P3 SURE entropy', 'Posterior P3 Skewness', 'Posterior P3 Kurtosis', \n",
    "              'Posterior alpha log energy entropy', 'Posterior alpha Shannon entropy', 'Posterior alpha SURE entropy', 'Posterior alpha Skewness',\n",
    "              'Posterior alpha Kurtosis']\n",
    "ap_features = totalDF[ap_columns]\n",
    "\n",
    "apb_columns = ['Posterior P3 mean', 'Posterior P3 STD', 'Posterior alpha mean', 'Alpha variability', 'Reaction time Mean', 'Reaction time variability', 'Accuracy',\n",
    "               'Posterior P3 log energy entropy', 'Posterior P3 Shannon entropy', 'Posterior P3 SURE entropy', 'Posterior P3 Skewness', 'Posterior P3 Kurtosis', \n",
    "               'Posterior alpha log energy entropy', 'Posterior alpha Shannon entropy', 'Posterior alpha SURE entropy', 'Posterior alpha Skewness',\n",
    "               'Posterior alpha Kurtosis']\n",
    "apb_features = totalDF[apb_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Correlation Matrix:\n",
    "corrMat = all_features.corr()\n",
    "plt.figure(figsize=(20,20))\n",
    "# sns.heatmap(corrMat, annot=True, cmap='Blues', fmt=\".2f\")\n",
    "\n",
    "# All features with correlation ge than .80:\n",
    "columns_to_drop = ['Frontal P3 log energy entropy','Frontal alpha log energy entropy', 'Frontal alpha Kurtosis', \n",
    "                   'Posterior P3 log energy entropy', 'Posterior alpha log energy entropy', 'Posterior alpha Kurtosis']\n",
    "uncorr_features = all_features.drop(columns=columns_to_drop, axis=1)\n",
    "# sns.heatmap(uncorr_features.corr(), annot=True, cmap='Blues', fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kendall's Tau Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kenmat = all_features.corr(method='kendall')\n",
    "# sns.heatmap(kenmat, annot=True, cmap='Blues', fmt=\".2f\")\n",
    "\n",
    "# All features with kendall correlation greater than .80\n",
    "columns_to_drop = ['Frontal P3 log energy entropy', 'Posterior P3 log energy entropy']\n",
    "kendall_features = all_features.drop(columns=columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features excluded:  ['Accuracy' 'Frontal P3 Kurtosis' 'Frontal alpha Skewness'\n",
      " 'Posterior P3 Skewness' 'Posterior P3 Kurtosis']\n"
     ]
    }
   ],
   "source": [
    "vt = VarianceThreshold(threshold=0.1)\n",
    "vt.fit(all_features)\n",
    "mask = vt.get_support()\n",
    "print(\"Features excluded: \", all_features.columns[~mask].values)\n",
    "vt_features = all_features.loc[:, mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectKBest - ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features excluded:  []\n"
     ]
    }
   ],
   "source": [
    "test = SelectKBest(score_func=f_classif, k=30)\n",
    "fit = test.fit(all_features, Y)\n",
    "mask = fit.get_support()\n",
    "print(\"Features excluded: \", all_features.columns[~mask].values)\n",
    "anova_features = all_features.loc[:, mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'AP' = alpha + posterior, 'APB' = alpha + posterior + behvaioural, 'all' = all features\n",
    "Select_features = 'kendalls'\n",
    "Notes = ''\n",
    "\n",
    "if Select_features == 'AP':\n",
    "    X = ap_features\n",
    "elif Select_features == 'APB':\n",
    "    X = apb_features\n",
    "elif Select_features == 'uncorr':\n",
    "    X = uncorr_features\n",
    "elif Select_features == 'vt':\n",
    "    X = vt_features\n",
    "elif Select_features == 'ANOVA':\n",
    "    X = anova_features\n",
    "elif Select_features == 'kendalls':\n",
    "    X = kendall_features\n",
    "else: \n",
    "    X = all_features\n",
    "    \n",
    "\n",
    "\n",
    "# print(X.columns)\n",
    "# Verify that Labels contain only 0 and 1:\n",
    "# print(X.Label.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables init\n",
    "Choose what type of KFold, which measures you would like, what info you would like to store in results. Some resources:\n",
    "- [svm](https://www.youtube.com/watch?v=efR1C6CvhmE)\n",
    "- [Gradient Boosting info](https://machinelearningmastery.com/gradient-boosting-with-scikit-learn-xgboost-lightgbm-and-catboost/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "index = []\n",
    "scores = {\"Accuracy\": [], \"BA\": [], \"Matt_Corr_Coef\": [], \"Cnf_Matr\": None, \"AUC\": []}\n",
    "results = {'Timestamp': [], 'Features': Select_features, 'CrossVal': type(kf).__name__, 'model': [], \"Accuracy\": [], \"BA\": [], \"Matt_Corr_Coef\": [], 'AUC': [], 'CnfM00': [], 'CnfM01': [], \n",
    "           'CnfM10': [], 'CnfM11': [], 'Notes': Notes}\n",
    "scoring = ['accuracy', 'balanced_accuracy', 'matthews_corrcoef']   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X, Y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "    \n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train_res, Y_train_res = sm.fit_resample(X_train, Y_train)\n",
    "    \n",
    "    normalized = 3\n",
    "    if normalized == 1:\n",
    "        scaler = StandardScaler()\n",
    "    elif normalized == 2:\n",
    "        scaler = MinMaxScaler()\n",
    "    elif normalized == 3:\n",
    "        scaler = Normalizer()\n",
    "    X_train = scaler.fit_transform(X_train_res)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for regressor in regressors:\n",
    "#     for train_index, test_index in kf.split(X, Y):\n",
    "#         X_train_kf, X_test_kf = X.iloc[train_index], X.iloc[test_index]\n",
    "#         y_train_kf, y_test_kf = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "#         sm = SMOTE(random_state=42)\n",
    "#         X_train, y_train = sm.fit_resample(X_train_kf, y_train_kf)\n",
    "        \n",
    "#         normalized = 3\n",
    "        \n",
    "#         sc = StandardScaler()\n",
    "#         mms = MinMaxScaler()\n",
    "#         ns = Normalizer()\n",
    "#         if normalized == 1:\n",
    "#             X_train = sc.fit_transform(X_train)\n",
    "#             X_test = sc.transform(X_test_kf)\n",
    "#         elif normalized == 2:\n",
    "#             X_train = mms.fit_transform(X_train)\n",
    "#             X_test = mms.transform(X_test_kf)\n",
    "#         elif normalized == 3:\n",
    "#             X_train = ns.fit_transform(X_train)\n",
    "#             X_test = ns.transform(X_test_kf)\n",
    "#         # X_train = pd.DataFrame(X_train_res, columns=all_features.columns)\n",
    "#         # X_test = pd.DataFrame(X_test_kf, columns=all_features.columns)\n",
    "                \n",
    "#         cv_results = cross_validate(regressor, X_train, y_train, cv=5, scoring=scoring)\n",
    "#         scores[\"Accuracy\"].append(cv_results['test_accuracy'].mean())\n",
    "#         scores[\"BA\"].append(cv_results['test_balanced_accuracy'].mean())\n",
    "#         scores[\"Matt_Corr_Coef\"].append(cv_results['test_matthews_corrcoef'].mean())\n",
    "#         cnf_matrix = metrics.confusion_matrix(y_test_kf, regressor.fit(X_train, y_train).predict(X_test))\n",
    "#         if scores[\"Cnf_Matr\"] is None:\n",
    "#             scores[\"Cnf_Matr\"] = cnf_matrix\n",
    "#         else:\n",
    "#             scores[\"Cnf_Matr\"] = np.mean(np.array([scores['Cnf_Matr'], cnf_matrix]), axis=0 )\n",
    "#         scores[\"AUC\"].append(metrics.roc_auc_score(y_test_kf, regressor.fit(X_train, y_train).predict(X_test)))\n",
    "        \n",
    "        \n",
    "#     print('\\n')\n",
    "#     print(type(regressor).__name__)\n",
    "#     results['model'].append(type(regressor).__name__)\n",
    "    \n",
    "#     for key in scores:\n",
    "#         if key != \"Cnf_Matr\":\n",
    "#             print(key, \":\", np.mean(scores[key]))\n",
    "#             results[key].append(np.mean(scores[key]))\n",
    "#     print(\"Cnf_Matr: \\n\", scores[\"Cnf_Matr\"])\n",
    "#     print(\"\\n\")    \n",
    "    \n",
    "#     results['CnfM00'].append(scores[\"Cnf_Matr\"][0][0])\n",
    "#     results['CnfM01'].append(scores[\"Cnf_Matr\"][0][1])\n",
    "#     results['CnfM10'].append(scores[\"Cnf_Matr\"][1][0])\n",
    "#     results['CnfM11'].append(scores[\"Cnf_Matr\"][1][1])\n",
    "#     results['Timestamp'].append(pd.Timestamp.now())\n",
    "    \n",
    "#     scores = {\"Accuracy\": [], \"BA\": [], \"Matt_Corr_Coef\": [], \"Cnf_Matr\": None, \"AUC\": []}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record Results\n",
    "Add these Results and Test Conditions to Results.xlsx. Will delete duplicate results within conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Timestamp, Features, CrossVal, model, Accuracy, BA, Matt_Corr_Coef, AUC, CnfM00, CnfM01, CnfM10, CnfM11, Notes, Normalized]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "results['Normalized'] = normalized\n",
    "df_newScores = pd.DataFrame(results)\n",
    "print(df_newScores)\n",
    "# df_existingRecord = pd.read_excel(results_file)\n",
    "# df_combined = pd.concat([df_existingRecord, df_newScores], ignore_index=True)\n",
    "# df_combined.drop_duplicates(subset=['Features', 'model', \"Accuracy\", \"BA\", \"Matt_Corr_Coef\", 'AUC', 'CnfM00', 'CnfM01', 'CnfM10', 'CnfM11', 'Notes'], keep='last', inplace = True)\n",
    "# df_combined.sort_values(by='Matt_Corr_Coef', ascending=False, inplace=True)\n",
    "# df_combined.to_excel(results_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "{'bootstrap': False, 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "randfor_param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [17, 19, 21],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "    'max_features': ['log2'],\n",
    "    'bootstrap': [False]\n",
    "}\n",
    "random_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), \n",
    "                             param_grid=randfor_param_grid, cv=10, verbose=2,\n",
    "                             n_jobs=-1, scoring='balanced_accuracy')\n",
    "\n",
    "# for train_index, test_index in kf.split(X, Y):\n",
    "#     X_train_kf, X_test_kf = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train_kf, y_test_kf = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "#     sm = SMOTE(random_state=42)\n",
    "#     X_train, y_train = sm.fit_resample(X_train_kf, y_train_kf)\n",
    "    \n",
    "#     normalized = 3\n",
    "#     ns = Normalizer()\n",
    "#     X_train = ns.fit_transform(X_train)\n",
    "#     X_test = ns.transform(X_test_kf)\n",
    "    \n",
    "#     random_search.fit(X_train, y_train)\n",
    "#     print(random_search.best_params_)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "normalized = 3\n",
    "ns = Normalizer()\n",
    "X_train = ns.fit_transform(X_train)\n",
    "X_test = ns.transform(X_test)\n",
    "random_search.fit(X_train, y_train)\n",
    "print(random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8599303135888501\n",
      "Test Accuracy: 0.462797619047619\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Accuracy: {random_search.best_score_}')\n",
    "print(f'Test Accuracy: {random_search.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost\n",
    "[Hyperparameter tutorial](https://www.geeksforgeeks.org/catboost-parameters-and-hyperparameters/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e287d6cd1246b597b03299664dd8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/5]\n",
      "0:\tlearn: 0.6711841\ttest: 0.6768894\tbest: 0.6768894 (0)\ttotal: 126ms\tremaining: 2m 6s\n",
      "200:\tlearn: 0.1565821\ttest: 0.5862259\tbest: 0.5624659 (46)\ttotal: 1.38s\tremaining: 5.48s\n",
      "400:\tlearn: 0.0662619\ttest: 0.6314215\tbest: 0.5624659 (46)\ttotal: 2.4s\tremaining: 3.58s\n",
      "600:\tlearn: 0.0365652\ttest: 0.6773662\tbest: 0.5624659 (46)\ttotal: 3.04s\tremaining: 2.02s\n",
      "800:\tlearn: 0.0240501\ttest: 0.7168340\tbest: 0.5624659 (46)\ttotal: 3.7s\tremaining: 919ms\n",
      "999:\tlearn: 0.0175629\ttest: 0.7446482\tbest: 0.5624659 (46)\ttotal: 4.44s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5624658572\n",
      "bestIteration = 46\n",
      "\n",
      "Training on fold [1/5]\n",
      "0:\tlearn: 0.6731328\ttest: 0.6774387\tbest: 0.6774387 (0)\ttotal: 3.92ms\tremaining: 3.91s\n",
      "200:\tlearn: 0.1569696\ttest: 0.5961190\tbest: 0.5679273 (57)\ttotal: 1.01s\tremaining: 4.02s\n",
      "400:\tlearn: 0.0664939\ttest: 0.6339287\tbest: 0.5679273 (57)\ttotal: 1.81s\tremaining: 2.7s\n",
      "600:\tlearn: 0.0376481\ttest: 0.6703753\tbest: 0.5679273 (57)\ttotal: 2.47s\tremaining: 1.64s\n",
      "800:\tlearn: 0.0246776\ttest: 0.6973283\tbest: 0.5679273 (57)\ttotal: 3.11s\tremaining: 773ms\n",
      "999:\tlearn: 0.0178246\ttest: 0.7292440\tbest: 0.5679273 (57)\ttotal: 3.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5679272561\n",
      "bestIteration = 57\n",
      "\n",
      "Training on fold [2/5]\n",
      "0:\tlearn: 0.6746530\ttest: 0.6759824\tbest: 0.6759824 (0)\ttotal: 10.1ms\tremaining: 10.1s\n",
      "200:\tlearn: 0.1512254\ttest: 0.6077993\tbest: 0.5612617 (42)\ttotal: 1.38s\tremaining: 5.5s\n",
      "400:\tlearn: 0.0625494\ttest: 0.6649466\tbest: 0.5612617 (42)\ttotal: 2.71s\tremaining: 4.05s\n",
      "600:\tlearn: 0.0350402\ttest: 0.7189167\tbest: 0.5612617 (42)\ttotal: 3.81s\tremaining: 2.53s\n",
      "800:\tlearn: 0.0230919\ttest: 0.7636011\tbest: 0.5612617 (42)\ttotal: 4.95s\tremaining: 1.23s\n",
      "999:\tlearn: 0.0166244\ttest: 0.8000911\tbest: 0.5612617 (42)\ttotal: 6.45s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5612616621\n",
      "bestIteration = 42\n",
      "\n",
      "Training on fold [3/5]\n",
      "0:\tlearn: 0.6716665\ttest: 0.6757552\tbest: 0.6757552 (0)\ttotal: 9.7ms\tremaining: 9.69s\n",
      "200:\tlearn: 0.1440421\ttest: 0.6833671\tbest: 0.5811790 (21)\ttotal: 1.27s\tremaining: 5.04s\n",
      "400:\tlearn: 0.0603664\ttest: 0.7719999\tbest: 0.5811790 (21)\ttotal: 2.53s\tremaining: 3.78s\n",
      "600:\tlearn: 0.0342523\ttest: 0.8261563\tbest: 0.5811790 (21)\ttotal: 3.71s\tremaining: 2.46s\n",
      "800:\tlearn: 0.0223671\ttest: 0.8722141\tbest: 0.5811790 (21)\ttotal: 5.15s\tremaining: 1.28s\n",
      "999:\tlearn: 0.0163238\ttest: 0.9151234\tbest: 0.5811790 (21)\ttotal: 6.31s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5811789956\n",
      "bestIteration = 21\n",
      "\n",
      "Training on fold [4/5]\n",
      "0:\tlearn: 0.6717066\ttest: 0.6738846\tbest: 0.6738846 (0)\ttotal: 5.09ms\tremaining: 5.08s\n",
      "200:\tlearn: 0.1550728\ttest: 0.6234402\tbest: 0.5685188 (40)\ttotal: 1.11s\tremaining: 4.4s\n",
      "400:\tlearn: 0.0664528\ttest: 0.6834591\tbest: 0.5685188 (40)\ttotal: 2.46s\tremaining: 3.68s\n",
      "600:\tlearn: 0.0369044\ttest: 0.7171675\tbest: 0.5685188 (40)\ttotal: 3.87s\tremaining: 2.57s\n",
      "800:\tlearn: 0.0241337\ttest: 0.7645369\tbest: 0.5685188 (40)\ttotal: 5.28s\tremaining: 1.31s\n",
      "999:\tlearn: 0.0173722\ttest: 0.7945775\tbest: 0.5685188 (40)\ttotal: 6.54s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5685187892\n",
      "bestIteration = 40\n",
      "\n",
      "['test-MultiClass-mean', 'test-MultiClass-std']\n"
     ]
    }
   ],
   "source": [
    "X = uncorr_features\n",
    "catboost_pool = Pool(X, label = Y)\n",
    "params = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.1,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'MultiClass',\n",
    "    'verbose': 200,\n",
    "    'random_state': 42\n",
    "}\n",
    "cv_results, cv_model = cv(catboost_pool, params, fold_count=5, plot=True, verbose=200, return_models=True, stratified=True)\n",
    "available_metrics = [metric for metric in cv_results.columns if 'test' in metric]\n",
    "print(available_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
